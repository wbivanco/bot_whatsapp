from typing import Any
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.schema import HumanMessage, SystemMessage

class LlmManager:
    """ Clase que maneja la carga y configuraci칩n de modelos de lenguaje y conversaci칩n. """  
    def __init__(self, llm_provider) -> None:
        self.llm_provider = llm_provider
    
    def initialice_llm_model(self, model_name, api_key, temperature=0):
        """ Carga el modelo y el api_key de OpenAI(pasados como par치metros obligatorios) y lo inicializa con la 
        temperatura deseada(por defecto es cero), se debe pasar el provider(empresa) del modelo, que indica que 
        clase de langchain se debe llamar.
        
        Args:
            model_name (str): Nombre del modelo.
            openai_api_key (str): Clave de API.
            temperature (float, optional): Temperatura del modelo. Por defecto es 0.
            system_prompt (str, optional): Prompt del sistema para inicializar el modelo. Por defecto es None.
    
        Returns:
            llm: Instancia del modelo inicializado. 
        """
       
        try:
            if self.llm_provider == "openai":
                llm = ChatOpenAI(                    
                    model_name=model_name, 
                    api_key=api_key,
                    temperature=temperature,                   
                )
        except Exception as e:
            print(f"Error al cargar el tipo de modelo LLM: {e}")
            llm = None    

        return llm
    
    def initialice_retriever(self, llm, stored_embeddings, search_type="similarity", num_result=1):
        """ Inicializa el modelo de recuperaci칩n de informaci칩n, pasando el modelo de lenguaje y los embeddings, 
        ademas se pueden pasar como par치metros el tipo de b칰squeda y la cantidad de resultados, ambos opcionales. """

        retriever = stored_embeddings.as_retriever(search_type=search_type, search_kwargs={"k": num_result})
        
        QA_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True 
        )

        return QA_chain

    def get_response_retriever(self, QA_chain, user_message, history):
        """ Recibe la cadena con el llm y retriever, adem치s de la pregunta del usuario y el historial del chat, devuelve \
            la respuesta del bot, de donde saco la informaci칩n y el historial. """
        messages = [
            SystemMessage(
                content="""Eres un asistente amigable y servicial para la Facultad de Humanidades de la Universidad Nacional de Catamarca.

REGLAS IMPORTANTES:
1. SOLO responde con informaci칩n que est칠 en los documentos PDF proporcionados
2. SIEMPRE responde en castellano (espa침ol argentino)
3. Usa un tono c치lido, amigable y cercano como si hablaras con un amigo
4. Si no tienes la informaci칩n espec칤fica, NO digas simplemente "no s칠"
5. En lugar de "no s칠", responde de forma amigable como: "춰Hola! Esa informaci칩n espec칤fica no la tengo en mis documentos, pero puedo ayudarte con otros tr치mites de la facultad. 쯊e interesa saber sobre [menciona alg칰n tema relacionado que s칤 tengas]?"

TU ROL:
- Ayudar a estudiantes con tr치mites administrativos
- Brindar informaci칩n sobre gesti칩n acad칠mica
- Orientar sobre vida universitaria
- Ser emp치tico y comprensivo con las dudas de los j칩venes

RECUERDA: Eres un compa침ero que quiere ayudar, no un robot fr칤o. Usa emojis ocasionalmente y mant칠n un lenguaje cercano pero respetuoso.

DESPU칄S DE CADA RESPUESTA:
- Si tu respuesta es completa y clara, termina ah칤
- Si tu respuesta podr칤a no ser suficiente o si crees que el usuario podr칤a tener m치s dudas, agrega al final:
  "쯊e queda alguna duda sobre este tema o necesitas informaci칩n sobre algo m치s?"
- Usa emojis para hacer la pregunta m치s amigable, por ejemplo: "游뱂 쯊e queda alguna duda sobre este tema o necesitas informaci칩n sobre algo m치s?" """
            ),  # System prompt
        ]

        # Agregar el historial de mensajes
        for msg in history:            
            messages.append(HumanMessage(content=msg["user"]))
            messages.append(HumanMessage(content=msg["assistant"]))   

        # Agregar el mensaje actual del usuario
        messages.append(HumanMessage(content=user_message))

        response = QA_chain.invoke({"query": user_message, "messages": messages})
        bot_response = response["result"]
        source_documents = response["source_documents"]
        
        # Extraer fuentes con metadatos adicionales (ej. t칤tulo, enlace)
        sources = []
        for doc in source_documents:
            source_info = {
                'source': doc.metadata.get('source', 'Desconocido'),  # Fuente original
                'title': doc.metadata.get('title', 'Sin t칤tulo'),  # T칤tulo del documento
                'url': doc.metadata.get('url', ''),  # Enlace si est치 disponible
                'snippet': doc.page_content[:200]  # Primeros 200 caracteres del documento
            }
            sources.append(source_info)
  
        return bot_response, sources

    def get_response_retriever_without_memory(self, QA_chain, user_message):
        """ Recibe la cadena con el llm y retriever y la pregunta del usuario, devuelve solo la respuesta del bot. """
        messages = [
            SystemMessage(
                content="""Eres un asistente para la Facultad de Humanidades de la Universidad Nacional de Catamarca.

INSTRUCCIONES CR칈TICAS:
1. SIEMPRE responde con informaci칩n de los documentos proporcionados
2. Si encuentras informaci칩n relacionada, comp치rtela aunque no sea exactamente lo que preguntan
3. NUNCA digas "no tengo informaci칩n" sin haber buscado exhaustivamente
4. Busca por palabras clave, sin칩nimos y t칠rminos relacionados
5. Responde en espa침ol argentino con tono amigable

EJEMPLO: Si preguntan sobre "Pr치ctica Docente", busca tambi칠n "pr치cticas", "docente", "cursar", "materia", etc.

IMPORTANTE: Siempre intenta encontrar informaci칩n 칰til en los documentos antes de decir que no tienes la informaci칩n.

DESPU칄S DE CADA RESPUESTA:
- Si tu respuesta es completa y clara, termina ah칤
- Si tu respuesta podr칤a no ser suficiente o si crees que el usuario podr칤a tener m치s dudas, agrega al final:
  "쯊e queda alguna duda sobre este tema o necesitas informaci칩n sobre algo m치s?"
- Usa emojis para hacer la pregunta m치s amigable, por ejemplo: "游뱂 쯊e queda alguna duda sobre este tema o necesitas informaci칩n sobre algo m치s?" """
            )
        ]
        messages.append(HumanMessage(content=user_message))
        response = QA_chain.invoke({"query": user_message, "messages": messages})
        bot_response = response["result"]
    
        return bot_response